{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"AME_508_Project_Case3.ipynb","provenance":[{"file_id":"1cDqW0s74frPsLgOfGvcVicgTDe6jeqQ-","timestamp":1638592824066},{"file_id":"1zi5N81cnFWrT9clVhAjquojPpGdj5BNy","timestamp":1638551593651},{"file_id":"1Kufgvq7Y6Rqp_isHff27QrWesrIdTWY6","timestamp":1638504093131},{"file_id":"1LGqrO6nCn3cspPG_7I2CLhGY-hsyMf2C","timestamp":1638464736651},{"file_id":"1iJYOmbhTKwGQo30A4uGte9WY6FYCnaC8","timestamp":1637968106525},{"file_id":"1fUiek3eeqmlD3XQ3Itw5YLT-ooiQaqx7","timestamp":1637952251693},{"file_id":"15vJuFkpwqtEYlNTmINg3u87llrXbJsPp","timestamp":1637816881914},{"file_id":"1U6pvTTQRs903hu1HEQDLLCowZ1HkExoJ","timestamp":1637453314888}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"pD5banC2Cu0G"},"source":["Tiansheng Wu, Chiao Hsiao, Junchao Ma"]},{"cell_type":"code","metadata":{"id":"MxmVq04pYCTq"},"source":["import math as m\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras\n","from keras.models import Sequential\n","from keras.layers import Dense\n","%matplotlib inline \n","import matplotlib.pyplot as plt\n","from matplotlib.gridspec import GridSpec\n","fsize = 15\n","plt.rcParams.update({'font.size': fsize})\n","from time import time"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KMlnS6tBzEkI"},"source":["Functions 1: Loss Function"]},{"cell_type":"code","metadata":{"id":"mcKlBQBEz6TZ"},"source":["#Define custom loss function\n","def loss_func(x_inp,x_bc_inp,x_ini_inp,u_inp,u_bc_inp,u_ini_inp,model,N,lambda_b):\n","  x = x_inp\n","\n","  u0_pred = model(x_ini_inp);\n","  u1_pred = model(x_bc_inp);\n","  loss_bc = lambda_b*tf.reduce_sum((u0_pred-u_ini_inp)**2 + (u1_pred-u_bc_inp)**2)/N;\n","\n","  # Get Burger's Eqn\n","  with tf.GradientTape() as g:\n","      g.watch(x)\n","      with tf.GradientTape() as gg:\n","        gg.watch(x)\n","        u = model(x)\n","      du_dtx = gg.batch_jacobian(u, x)\n","      du_dt = du_dtx[..., 0]\n","      du_dx = du_dtx[..., 1]\n","  d2u_dx2 = g.batch_jacobian(du_dx, x)[..., 1]\n","\n","  res = du_dt + u*du_dx - x[...,2]*d2u_dx2\n","\n","  # Interior loss\n","  loss = tf.reduce_sum(res**2)/N; # calculate interior N samples* nu layers\n","  loss = tf.cast(loss, tf.float32);\n","\n","  # Inital loss\n","  loss = loss + loss_bc\n","\n","  return loss"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NnkSEl9nzOpS"},"source":["Function 2: construct model"]},{"cell_type":"code","metadata":{"id":"XGuKkmMuzNYS"},"source":["def construct_model(Input_Dim,Output_Dim,width,depth,reg_param):\n","  model = Sequential();\n","\n","  # Construct layers\n","  model.add(keras.Input(shape = (Input_Dim,))); #input\n","\n","  for i in range(depth):\n","    if i == 0: # first layer, tanh activation\n","      model.add(Dense(width,\n","              kernel_initializer = 'RandomNormal', # initialization varies at each call of function\n","              bias_initializer = 'RandomNormal',\n","              kernel_regularizer = tf.keras.regularizers.l2(reg_param), # introduce L2 regularization for weight and bias\n","              bias_regularizer = tf.keras.regularizers.l2(reg_param),\n","              activation=\"tanh\"));\n","\n","    elif i == depth-1: # output layer, no activation\n","      model.add(Dense(output_dim,\n","              input_dim = width,\n","              kernel_initializer = 'RandomNormal', # initialization varies at each call of function\n","              bias_initializer = 'RandomNormal',\n","              kernel_regularizer = tf.keras.regularizers.l2(reg_param), # introduce L2 regularization for weight and bias\n","              bias_regularizer = tf.keras.regularizers.l2(reg_param),\n","              activation=\"tanh\"));\n","\n","    else: # intermediate hidden layers, tanh activations\n","      model.add(Dense(width,\n","              input_dim = width,\n","              kernel_initializer = 'RandomNormal', # initialization varies at each call of function\n","              bias_initializer = 'RandomNormal',\n","              kernel_regularizer = tf.keras.regularizers.l2(reg_param), # introduce L2 regularization for weight and bias\n","              bias_regularizer = tf.keras.regularizers.l2(reg_param),\n","              activation=\"tanh\"));\n","  return model"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"keaQQ0yPzv_R"},"source":["Parameters"]},{"cell_type":"code","metadata":{"id":"klyjkCyVmIkm"},"source":["# define model params\n","width = 16;\n","depth = 4;\n","input_dim = 3;\n","output_dim = 1;\n","reg_param = 1e-7;\n","lambda_b = 100;\n","N = 10000;\n","max_epoch = 10000;\n","\n","# interior conditions\n","np.random.seed(54)\n","x_int = np.random.rand(N,3); # [t;x;nu], both [0,1]\n","x_int[...,1] = 2*(x_int[...,1]-0.5); # shift x to [-1,1]\n","x_int[...,2] = (x_int[...,2]+0.00001)*9/100; # nu selected from ~0 to 0.09\n","u_int = np.zeros((N,1));\n","\n","# initial conditions\n","x_ini = np.random.rand(N,3);\n","x_ini[...,0] = 0; #t = 0\n","x_ini[...,1] = 2*(x_ini[...,1]-0.5); # x, -1 to 1\n","x_int[...,2] = (x_int[...,2]+0.00001)*9/100; # nu selected from ~0 to 0.09\n","u_ini = np.sin(-np.pi * x_ini[...,1]).reshape(N,1);\n","\n","# boundary conditions\n","x_bc = np.random.rand(N,3); # t, 0 to 1\n","x_bc_list = [-1,1]\n","x_bc[...,1] = np.random.choice(x_bc_list,1); # -1 or 1\n","x_int[...,2] = (x_int[...,2]+0.00001)*9/100; # nu selected from ~0 to 0.09\n","u_bc = np.zeros((N,1));\n","\n","# merge inputs\n","x_bc_inp = [x_bc]\n","x_ini_inp = [x_ini]\n","x_inp = [x_int]\n","u_bc_inp = [u_bc]\n","u_ini_inp = [u_ini]\n","u_inp = [u_int]\n","\n","x_inp = tf.reshape(x_inp,(-1,3));\n","x_inp = tf.cast(x_inp, tf.float32);\n","u_inp = tf.reshape(u_inp,(-1,1));\n","u_inp = tf.cast(u_inp, tf.float32);\n","\n","x_bc_inp = tf.reshape(x_bc_inp,(-1,3));\n","x_bc_inp = tf.cast(x_bc_inp, tf.float32);\n","u_bc_inp = tf.reshape(u_bc_inp,(-1,1));\n","u_bc_inp = tf.cast(u_bc_inp, tf.float32);\n","\n","x_ini_inp = tf.reshape(x_ini_inp,(-1,3));\n","x_ini_inp = tf.cast(x_ini_inp, tf.float32);\n","u_ini_inp = tf.reshape(u_ini_inp,(-1,1));\n","u_ini_inp = tf.cast(u_ini_inp, tf.float32);"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"V-9rhGEE4R2o"},"source":["Train Model"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6FHZtcDvXbZD","executionInfo":{"status":"ok","timestamp":1638550999560,"user_tz":480,"elapsed":9,"user":{"displayName":"Tiansheng Wu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02748899716923494974"}},"outputId":"a1006fd9-86e9-49f4-f1bf-1e953e2c50ae"},"source":["\n","int_loss_dict = {}\n","bnd_loss_dict = {}\n","total_loss_dict = {}\n","pred_dict = {}\n","\n","int_loss_loc = np.zeros(max_epoch)\n","bnd_loss_loc = np.zeros(max_epoch)\n","total_loss_loc = np.zeros(max_epoch)\n","\n","tf.keras.backend.clear_session()\n","model = construct_model(input_dim,output_dim,width,depth,reg_param)\n","model.summary()\n","optimizer = keras.optimizers.Adam(learning_rate=1e-3)\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense (Dense)               (None, 16)                64        \n","                                                                 \n"," dense_1 (Dense)             (None, 16)                272       \n","                                                                 \n"," dense_2 (Dense)             (None, 16)                272       \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 17        \n","                                                                 \n","=================================================================\n","Total params: 625\n","Trainable params: 625\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","metadata":{"id":"lZii4sZWML5M","colab":{"base_uri":"https://localhost:8080/"},"outputId":"14fcd67f-5192-479b-c7da-09398af3a78d"},"source":["\n","# Train Model\n","for epoch in range(max_epoch):\n","  #print(epoch)\n","  with tf.GradientTape() as tape:\n","\n","    loss = loss_func(x_inp,x_bc_inp,x_ini_inp,u_inp,u_bc_inp,u_ini_inp,model,N,lambda_b)\n","    loss += sum(model.losses)\n","\n","    # Report History\n","    if (epoch+1)%(max_epoch) == 0 or (epoch+1)%250 == 0 or (epoch+1) == 1:\n","      print(\"Epoch: \",(epoch+1),\"; loss: \",loss.numpy())\n","\n","  grads = tape.gradient(loss, model.trainable_variables)\n","\n","  optimizer.apply_gradients(zip(grads, model.trainable_variables))\n","  total_loss_loc[epoch] = loss.numpy()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch:  1 ; loss:  50.321445\n","WARNING:tensorflow:5 out of the last 5 calls to <function pfor.<locals>.f at 0x7f1ee0426d40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","WARNING:tensorflow:6 out of the last 6 calls to <function pfor.<locals>.f at 0x7f1ee0426f80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","Epoch:  250 ; loss:  41.110165\n"]}]},{"cell_type":"code","metadata":{"id":"0rB4f5Dwuy3k"},"source":["plt.figure()\n","plt.semilogy(total_loss_loc)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Tncx32YtvFlY"},"source":["Plot Training Results"]},{"cell_type":"code","metadata":{"id":"5w_4SMBxdGSQ"},"source":["# predict u(t,x) distribution\n","t_span = np.linspace(0, 1, N)\n","x_span = np.linspace(-1, 1, N)\n","nu_span = np.ones(N)*0.001\n","t, x= np.meshgrid(t_span, x_span)\n","nu_val = np.ones((N,N))\n","\n","\n","plt.figure(figsize=(10,10))\n","ax = plt.axes(projection='3d')\n","\n","nu_val[:, :] = 0.001\n","txnu = np.stack([t.flatten(), x.flatten(), nu_val.flatten()], axis=-1)\n","u = model.predict(txnu, batch_size=N)\n","u = u.reshape(t.shape)\n","\n","ax.contour3D(t_span, x_span, u, 300, cmap='binary')\n","ax.set_xlabel('t')\n","ax.set_ylabel('x')\n","ax.set_zlabel('u')\n","ax.set_title('nu = 0.001', fontsize=20)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YuDTAbPwtjun"},"source":["# predict u(t,x) distribution\n","t_span = np.linspace(0, 1, N)\n","x_span = np.linspace(-1, 1, N)\n","null_span = np.ones(N)*0.001\n","t, x= np.meshgrid(t_span, x_span)\n","nu_val = np.ones((N,N))\n","nu_val[:, :] = 0.001\n","txnu = np.stack([t.flatten(), x.flatten(), nu_val.flatten()], axis=-1)\n","u = model.predict(txnu, batch_size=N)\n","u = u.reshape(t.shape)\n","\n","fig = plt.figure(figsize=(14,4))\n","gs = GridSpec(2, 6)\n","plt.subplot(gs[0, :])\n","plt.pcolormesh(t, x, u, cmap='rainbow')\n","plt.xlabel('t')\n","plt.ylabel('x')\n","cbar = plt.colorbar(pad=0.05, aspect=10)\n","cbar.set_label('u(t,x)')\n","cbar.mappable.set_clim(-1, 1)\n","\n","t_cross_sections = [0,0.2,0.4,0.6,0.8,1]\n","for i, t_cs in enumerate(t_cross_sections):\n","    plt.subplot(gs[1, i])\n","    txnu = np.stack([np.full(t_span.shape, t_cs), x_span, nu_span], axis=-1)\n","    u = model.predict(txnu, batch_size=N)\n","    plt.plot(x_span, u)\n","    plt.title('t={}'.format(t_cs))\n","    plt.xlabel('x')\n","    plt.ylabel('u(t,x)')\n","plt.tight_layout()\n","plt.show()"],"execution_count":null,"outputs":[]}]}